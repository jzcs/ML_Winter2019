{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Perceptrons\n",
    "### Due Thursday, January 17, 2019, 5pm\n",
    "#### Jesse Zhu\n",
    "#### ML-W2019\n",
    "\n",
    "Using the MNIST hand-written digits dataset, we aim to use perceptrons to categorize the labeled data through supervised learning. As this is a single-layer, the result is not expected to be perfect, but should be noticeably better than random. Each data point will be 785 values between 0 and 1, representing the grayscale value of each pixel in the original image. These values will be used to update our weight values over the course of 50 epochs, resulting in our 10 perceptrons (digits 0 to 9) being trained at the end. Finally, we will run test data through these trained perceptrons and take the maximum value of the 10 perceptrons as the predicted result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DATA#################\n",
    "testfile = \"mnist_test.csv\"\n",
    "trainfile = \"mnist_train.csv\"\n",
    "\n",
    "# test_data = pd.read_csv(testfile)\n",
    "# train_data = pd.read_csv(trainfile)\n",
    "\n",
    "#Data is 785 columns by N rows. First column = Label (0-9), others = 0:255\n",
    "test_data = np.genfromtxt(testfile, skip_header=True, delimiter=',')\n",
    "train_data = np.genfromtxt(trainfile, skip_header=True, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.45490196\n",
      " 0.49019608 0.67058824 1.         1.         0.58823529 0.36470588\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.6627451  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.85490196 0.11764706 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.6627451\n",
      " 0.99215686 0.99215686 0.99215686 0.83529412 0.55686275 0.69019608\n",
      " 0.99215686 0.99215686 0.47843137 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20392157 0.98039216 0.99215686 0.82352941\n",
      " 0.1254902  0.04705882 0.         0.02352941 0.80784314 0.99215686\n",
      " 0.54901961 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30196078 0.98431373 0.82352941 0.09803922 0.         0.\n",
      " 0.         0.47843137 0.97254902 0.99215686 0.25490196 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12156863\n",
      " 0.07058824 0.         0.         0.         0.         0.81960784\n",
      " 0.99215686 0.99215686 0.25490196 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.45882353 0.96862745 0.99215686 0.77647059\n",
      " 0.03921569 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29803922\n",
      " 0.96862745 0.99215686 0.90588235 0.24705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.50196078 0.99215686 0.99215686\n",
      " 0.56470588 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.69019608 0.96470588 0.99215686 0.62352941 0.04705882 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09803922 0.91764706 0.99215686\n",
      " 0.91372549 0.1372549  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.77647059 0.99215686 0.99215686 0.55294118 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.30588235 0.97254902\n",
      " 0.99215686 0.74117647 0.04705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0745098  0.78431373 0.99215686 0.99215686 0.55294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5254902\n",
      " 0.99215686 0.99215686 0.67843137 0.04705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.97254902 0.99215686 0.99215686\n",
      " 0.09803922 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97254902 0.99215686 0.99215686 0.16862745 0.07843137\n",
      " 0.07843137 0.07843137 0.07843137 0.01960784 0.         0.01960784\n",
      " 0.07843137 0.07843137 0.14509804 0.58823529 0.58823529 0.58823529\n",
      " 0.57647059 0.03921569 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.97254902\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.65882353 0.56078431 0.65098039 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.68235294 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.97647059 0.96862745 0.96862745\n",
      " 0.6627451  0.45882353 0.45882353 0.22352941 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.4627451  0.48235294 0.48235294 0.48235294\n",
      " 0.65098039 0.99215686 0.99215686 0.99215686 0.60784314 0.48235294\n",
      " 0.48235294 0.16078431 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESSING###############\n",
    "\n",
    "#SCALE by 255\n",
    "test_data[:,1:] /= 255\n",
    "train_data[:,1:] /= 255\n",
    "print((test_data[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04631771  0.00114123  0.00894236  0.04313398  0.04093737  0.02829112\n",
      "  0.00319776 -0.03990701  0.03173384  0.00164862]\n"
     ]
    }
   ],
   "source": [
    "#SHUFFLE (not required this assignment)\n",
    "\n",
    "#print((test_data[0,:]))\n",
    "\n",
    "#INITIALIZE RANDOM WEIGHTS\n",
    "#785,10\n",
    "init_weights = (np.random.rand(785,10) * 0.10) - 0.05\n",
    "\n",
    "learning_rates = [0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuraccy function\n",
    "def acc(weights, data, debug = 0):\n",
    "    \"\"\"input: \n",
    "        weights: matrix of 785 weights by 10 classes, where the first weight is the bias\n",
    "        data: matrix of N data points by 785 values, where the first value is the target (0-9), and the rest are\n",
    "            scaled gray-scale values between 0 and 1\n",
    "        output: Percentage of correct classifications, where a classification is taken using the highest perceptron\n",
    "            output value\n",
    "    \"\"\"\n",
    "    ret = 0\n",
    "    length = len(data[:,0])\n",
    "    out = data[:, 1:] @ weights[1:, :]\n",
    "    print(out.shape)\n",
    "    amax = out.argmax(axis=1)\n",
    "    print(amax[0:25])\n",
    "    ret = np.sum(amax == data[:,0])\n",
    "    return ret/length\n",
    "\n",
    "#Drawing function\n",
    "def draw_digit(data):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        1x785 matrix of grayscaled pixel values\n",
    "    output: image of (1:785 pixels, skipping first label)\n",
    "    \"\"\"\n",
    "    img = np.reshape(data[1:], (28, 28))\n",
    "    print(img)\n",
    "    plt.imshow(img)\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 10)\n",
      "[7 1 7 7 1 3 7 4 1 7 1 7 7 7 1 1 1 1 1 1 7 1 7 1 7]\n",
      "0.07200720072007201\n"
     ]
    }
   ],
   "source": [
    "w = init_weights\n",
    "print(acc(w, test_data))\n",
    "#draw_digit(test_data[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix of Resources\n",
    "1. Matrix multiplication\n",
    "https://stackoverflow.com/questions/21562986/numpy-matrix-vector-multiplication\n",
    "\n",
    "```a = np.random.rand(1,3)\n",
    "b = np.random.rand(3,5)\n",
    "print(a@b)\n",
    "\n",
    "print(np.zeros([3,3]))\n",
    "```\n",
    "\n",
    "2. Argmax arrays\n",
    "https://stackoverflow.com/questions/5469286/how-to-get-the-index-of-a-maximum-element-in-a-numpy-array-along-one-axis\n",
    "```\n",
    "mm.argmax(axis=1)\n",
    "```\n",
    "\n",
    "3. Plotting 2d arrays\n",
    "https://stackoverflow.com/questions/16492830/colorplot-of-2d-array-matplotlib\n",
    "\n",
    "4. Count # Equal Array Elements\n",
    "https://stackoverflow.com/questions/25490641/check-how-many-elements-are-equal-in-two-numpy-arrays-python\n",
    "```\n",
    "np.sum(a == b)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
