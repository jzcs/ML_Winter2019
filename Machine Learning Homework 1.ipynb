{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Perceptrons\n",
    "### Due Thursday, January 17, 2019, 5pm\n",
    "#### Jesse Zhu\n",
    "#### ML-W2019\n",
    "\n",
    "Using the MNIST hand-written digits dataset, we aim to use perceptrons to categorize the labeled data through supervised learning. As this is a single-layer, the result is not expected to be perfect, but should be noticeably better than random. Each data point will be 785 values between 0 and 1, representing the grayscale value of each pixel in the original image. These values will be used to update our weight values over the course of 50 epochs, resulting in our 10 perceptrons (digits 0 to 9) being trained at the end. Finally, we will run test data through these trained perceptrons and take the maximum value of the 10 perceptrons as the predicted result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DATA#################\n",
    "testfile = \"mnist_test.csv\"\n",
    "trainfile = \"mnist_train.csv\"\n",
    "\n",
    "# test_data = pd.read_csv(testfile)\n",
    "# train_data = pd.read_csv(trainfile)\n",
    "\n",
    "#Data is 785 columns by N rows. First column = Label (0-9), others = 0:255\n",
    "test_data = np.genfromtxt(testfile, skip_header=True, delimiter=',')\n",
    "train_data = np.genfromtxt(trainfile, skip_header=True, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.45490196\n",
      " 0.49019608 0.67058824 1.         1.         0.58823529 0.36470588\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.6627451  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.85490196 0.11764706 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.6627451\n",
      " 0.99215686 0.99215686 0.99215686 0.83529412 0.55686275 0.69019608\n",
      " 0.99215686 0.99215686 0.47843137 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.20392157 0.98039216 0.99215686 0.82352941\n",
      " 0.1254902  0.04705882 0.         0.02352941 0.80784314 0.99215686\n",
      " 0.54901961 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.30196078 0.98431373 0.82352941 0.09803922 0.         0.\n",
      " 0.         0.47843137 0.97254902 0.99215686 0.25490196 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12156863\n",
      " 0.07058824 0.         0.         0.         0.         0.81960784\n",
      " 0.99215686 0.99215686 0.25490196 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.45882353 0.96862745 0.99215686 0.77647059\n",
      " 0.03921569 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29803922\n",
      " 0.96862745 0.99215686 0.90588235 0.24705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.50196078 0.99215686 0.99215686\n",
      " 0.56470588 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.69019608 0.96470588 0.99215686 0.62352941 0.04705882 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09803922 0.91764706 0.99215686\n",
      " 0.91372549 0.1372549  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.77647059 0.99215686 0.99215686 0.55294118 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.30588235 0.97254902\n",
      " 0.99215686 0.74117647 0.04705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0745098  0.78431373 0.99215686 0.99215686 0.55294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.5254902\n",
      " 0.99215686 0.99215686 0.67843137 0.04705882 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.97254902 0.99215686 0.99215686\n",
      " 0.09803922 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97254902 0.99215686 0.99215686 0.16862745 0.07843137\n",
      " 0.07843137 0.07843137 0.07843137 0.01960784 0.         0.01960784\n",
      " 0.07843137 0.07843137 0.14509804 0.58823529 0.58823529 0.58823529\n",
      " 0.57647059 0.03921569 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.97254902\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.65882353 0.56078431 0.65098039 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.68235294 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.97647059 0.96862745 0.96862745\n",
      " 0.6627451  0.45882353 0.45882353 0.22352941 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.4627451  0.48235294 0.48235294 0.48235294\n",
      " 0.65098039 0.99215686 0.99215686 0.99215686 0.60784314 0.48235294\n",
      " 0.48235294 0.16078431 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESSING###############\n",
    "\n",
    "#SCALE by 255\n",
    "test_data[:,1:] /= 255\n",
    "train_data[:,1:] /= 255\n",
    "print((test_data[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04631771  0.00114123  0.00894236  0.04313398  0.04093737  0.02829112\n",
      "  0.00319776 -0.03990701  0.03173384  0.00164862]\n"
     ]
    }
   ],
   "source": [
    "#SHUFFLE (not required this assignment)\n",
    "\n",
    "#print((test_data[0,:]))\n",
    "\n",
    "#INITIALIZE RANDOM WEIGHTS\n",
    "#785,10\n",
    "init_weights = (np.random.rand(785,10) * 0.10) - 0.05\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuraccy function\n",
    "def acc(weights, data, debug = 0):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        weights: matrix of 785 weights by 10 classes, where the first weight is the bias\n",
    "        data: matrix of N data points by 785 values, where the first value is the target (0-9), and the rest are\n",
    "            scaled gray-scale values between 0 and 1\n",
    "    output: Percentage of correct classifications, where a classification is taken using the highest perceptron\n",
    "        output value\n",
    "    \"\"\"\n",
    "    length = len(data[:,0])\n",
    "    out = data[:, 1:] @ weights[1:, :]\n",
    "    amax = out.argmax(axis=1)\n",
    "    if debug:\n",
    "        print(out.shape)\n",
    "        print(amax[0:25])\n",
    "    ret = np.sum(amax == data[:,0])\n",
    "    return ret/length\n",
    "\n",
    "#Drawing function\n",
    "def draw_digit(data):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        1x785 matrix of grayscaled pixel values\n",
    "    output: image of (1:785 pixels, skipping first label)\n",
    "    \"\"\"\n",
    "    img = np.reshape(data[1:], (28, 28))\n",
    "    print(img)\n",
    "    plt.imshow(img)\n",
    "    plt.show\n",
    "    \n",
    "#Training function\n",
    "def train(weights, data, lr, debug = 0):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        weights: matrix of 785 weights by 10 classes, where the first weight is the bias\n",
    "        data: matrix of N data points by 785 values, where the first value is the target (0-9), and the rest are\n",
    "            scaled gray-scale values between 0 and 1\n",
    "        lr: learning rate (~ 0 to 1)\n",
    "    output:\n",
    "        Altered input weights matrix\n",
    "    \"\"\"\n",
    "    length = len(data[:,0])\n",
    "\n",
    "    for i in range(0,length):\n",
    "        xi = np.append([1], data[i, 1:]) #add \"1\" to input beginning for offset -> 1x785\n",
    "        out = np.add((data[i, 1:] @ weights[1:, :]), weights[0, :]) #1 by 10 matrix\n",
    "\n",
    "        target = np.zeros(10)\n",
    "        tindex = int(data[i,0])\n",
    "        target[tindex] = 1 #1x10 of 0s, with target index = 1\n",
    "      \n",
    "        out[out < 0] = 0\n",
    "        out[out > 0] = 1\n",
    "        if i == 0 and debug:\n",
    "            print(target-out)\n",
    "\n",
    "        deltaw = lr * np.outer(xi,(target - out)) #785x1 * 1x10 = 785x10\n",
    "        if i == 0 and debug:\n",
    "            print(deltaw[0:10,0:5])\n",
    "            print(xi[0:10])\n",
    "            print(deltaw.sum())\n",
    "            print(weights.sum())\n",
    "\n",
    "        weights += deltaw\n",
    "        if i == 0 and debug:\n",
    "            print(weights.sum())\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8066513604599492\n",
      "0.07200720072007201\n",
      "0.8362836283628363\n",
      "-569.5804074630694\n"
     ]
    }
   ],
   "source": [
    "#draw_digit(test_data[0, :])\n",
    "w = init_weights\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "\n",
    "rate = 0.1\n",
    "acc_test.append(acc(w, test_data, debug = 0))\n",
    "acc_train.append(acc(w, train_data, debug = 0))\n",
    "\n",
    "train(w, test_data, 0.1)\n",
    "\n",
    "print(acc(w, test_data, debug = 0))\n",
    "print(w.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix of Resources\n",
    "1. Matrix multiplication\n",
    "https://stackoverflow.com/questions/21562986/numpy-matrix-vector-multiplication\n",
    "\n",
    "```python\n",
    "a = np.random.rand(1,3)\n",
    "b = np.random.rand(3,5)\n",
    "print(a@b)\n",
    "\n",
    "print(np.zeros([3,3]))\n",
    "\n",
    "np.add([1, 2, 3], [5, 5, 0])\n",
    "```\n",
    "\n",
    "2. Argmax arrays\n",
    "https://stackoverflow.com/questions/5469286/how-to-get-the-index-of-a-maximum-element-in-a-numpy-array-along-one-axis\n",
    "```python\n",
    "mm.argmax(axis=1)\n",
    "```\n",
    "\n",
    "3. Plotting 2d arrays\n",
    "https://stackoverflow.com/questions/16492830/colorplot-of-2d-array-matplotlib\n",
    "\n",
    "4. Count # Equal Array Elements\n",
    "https://stackoverflow.com/questions/25490641/check-how-many-elements-are-equal-in-two-numpy-arrays-python\n",
    "```python\n",
    "np.sum(a == b)\n",
    "```\n",
    "\n",
    "5. Multiplying 1-D arrays / transposing\n",
    "https://stackoverflow.com/questions/23566515/multiplication-of-1d-arrays-in-numpy\n",
    "```python\n",
    "b[:, None]\n",
    "```\n",
    "\n",
    "6. Positive/Negative values -> 1, 0\n",
    "https://stackoverflow.com/questions/10335090/numpy-replace-negative-values-in-array\n",
    "\n",
    "```python\n",
    "f = np.array([-2, -1, 0, 0, 3, 5, -4])\n",
    "f[f < 0] = 0\n",
    "f[f > 0] = 1\n",
    "```\n",
    "\n",
    "7. Python numpy references vs call by reference?\n",
    "https://stackoverflow.com/questions/11585793/are-numpy-arrays-passed-by-reference/11585888\n",
    "`weights = np.add(weights, deltaw) #DOES NOT WORK`\n",
    "\n",
    "`weights += blah` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [28 32 36]]\n",
      "[[  6   5   4]\n",
      " [ -7  -9 -11]]\n",
      "[ 1.  1.  1. -0. -0. -0.]\n",
      "[[0 0 1]\n",
      " [0 0 2]\n",
      " [0 0 3]\n",
      " [0 0 4]\n",
      " [0 0 5]]\n",
      "[0 0 0 0 1 1 0]\n",
      "[0. 0. 0. 0. 1.]\n",
      "[[10 10 10]\n",
      " [20 20 20]\n",
      " [30 30 30]\n",
      " [40 40 40]\n",
      " [50 50 50]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = [10, 11, 12]\n",
    "a[1,:] = np.add(a[1,:], b)\n",
    "print(2*a)\n",
    "print(7-a)\n",
    "c = np.array([0.1, 0.2, 0.3, -0.4, -0.5, -0.6])\n",
    "print(np.ceil(c))\n",
    "d = np.array([[1, 2, 3, 4, 5]])\n",
    "e = np.array([[0, 0, 1]])\n",
    "print(np.transpose(d)@e)\n",
    "f = np.array([-2, -1, 0, 0, 3, 5, -4])\n",
    "f[f < 0] = 0\n",
    "f[f > 0] = 1\n",
    "print(f)\n",
    "g = np.zeros(5)\n",
    "g[4] = 1\n",
    "print(g)\n",
    "a1 = [1, 2, 3, 4, 5]\n",
    "b1 = [10, 10, 10]\n",
    "print(np.outer(a1,b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
