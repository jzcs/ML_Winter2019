{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Naive Bayes Classification and Logistic Regression\n",
    "Due Tuesday Feb 21 5 PM\n",
    "\n",
    "In this assignment, we use the UCI spam email database (https://archive.ics.uci.edu/ml/datasets/Spambase) and analyse it using Gaussian Naive Bayes and Logistic Regression.\n",
    "\n",
    "## Part 1: Classification with Naive Bayes\n",
    "\n",
    "Here, we use the Gaussian Naive Bayes algorithm (https://en.wikipedia.org/wiki/Naive_Bayes_classifier).\n",
    "\n",
    "First, we split the data set equally into training and test sets, and note that spam constitutes ~39% of the data. We then compute the means and standard deviations with respect to each of the 57 classes, for both the spam and not-spam training groups. This constitutes our probabilistic model which we then feed into the Naive Bayes classifier equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n",
      "(4601, 57)\n",
      "(4601,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "spamdata = pd.read_csv(\"spambase.data\", header = None)\n",
    "\n",
    "spamdata.head()\n",
    "spam = spamdata.values #to numpy matrix\n",
    "print(spam.shape)\n",
    "#print(spam[0,:])\n",
    "data = spam[:,:-1] \n",
    "label = spam[:,-1]\n",
    "\n",
    "#Split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.50, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total set: \t prior_spam = 0.39 \t prior_not = 0.61\n",
      "training set: \t prior_spam = 0.39 \t prior_not = 0.61\n",
      "test set: \t prior_spam = 0.39 \t prior_not = 0.61\n"
     ]
    }
   ],
   "source": [
    "# Probabilistic Model\n",
    "\n",
    "#Prior Probability for each class\n",
    "prior_spam = sum(label) / len(label)\n",
    "prior_not = 1 - prior_spam\n",
    "print(\"total set: \\t prior_spam = {0:0.2f} \\t prior_not = {1:0.2f}\".format(prior_spam, prior_not))\n",
    "\n",
    "#Verifying training / test sets\n",
    "prior_train_spam = sum(y_train) / len(y_train)\n",
    "prior_train_not = 1 - prior_train_spam\n",
    "print(\"training set: \\t prior_spam = {0:0.2f} \\t prior_not = {1:0.2f}\".format(prior_train_spam, prior_train_not))\n",
    "\n",
    "prior_test_spam = sum(y_test) / len(y_test)\n",
    "prior_test_not = 1 - prior_test_spam\n",
    "print(\"test set: \\t prior_spam = {0:0.2f} \\t prior_not = {1:0.2f}\".format(prior_test_spam, prior_test_not))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2300, 58)\n",
      "found first 1-class @ i =\n",
      "1394\n",
      "(1394, 57)\n",
      "(906, 57)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Mean and standard Deviation of training set\n",
    "epsilon = 0.0001 #Add to standard deviation if 0\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(np.mean(X_train[:,0]))\n",
    "X_train_means = X_train.mean(axis=0)\n",
    "X_train_stds = X_train.std(axis=0)\n",
    "print(np.count_nonzero(X_train_stds == 0))\n",
    "\n",
    "#Concat data + labels, and sort by label\n",
    "X_joined = np.concatenate((X_train, y_train.reshape(-1,1)), axis=1)\n",
    "print(X_joined.shape)\n",
    "X_joined_sorted = sorted(X_joined, key=lambda x: x[57])\n",
    "split_i = 0\n",
    "for i in range(2300):\n",
    "    if X_joined_sorted[i][57] == 1:\n",
    "        print(\"found first 1-class @ i =\")\n",
    "        split_i = i\n",
    "        break\n",
    "print(split_i)\n",
    "X_joined_sorted = np.array(X_joined_sorted)\n",
    "X_train_not = X_joined_sorted[0:1394,:-1]\n",
    "X_train_spam = X_joined_sorted[1394:,:-1]\n",
    "print(X_train_not.shape)\n",
    "print(X_train_spam.shape)\n",
    "\n",
    "#Not spam mean, std\n",
    "not_means = X_train_not.mean(axis=0)\n",
    "not_stds = X_train_not.std(axis=0)\n",
    "print(np.count_nonzero(not_stds == 0))\n",
    "#Spam mean, std\n",
    "spam_means = X_train_spam.mean(axis=0)\n",
    "spam_stds = X_train_spam.std(axis=0)\n",
    "print(np.count_nonzero(spam_stds == 0)) #no need for +epsilon since no 0-standard deviations found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2301, 2)\n"
     ]
    }
   ],
   "source": [
    "#Running Naive Bayes on test data\n",
    "not_minus_mu_sq = (X_test - not_means)**2\n",
    "spam_minus_mu_sq = (X_test - spam_means)**2\n",
    "\n",
    "#X_minus_mu_sq = (X_test - X_train_means)**2\n",
    "#X_train_stds_sq = X_train_stds**2\n",
    "#print(X_minus_mu[0:2,25:33])\n",
    "#print(X_test[0:2, 25:33])\n",
    "#print(X_train_means[25:33])\n",
    "#print(X_minus_mu_sq.shape)\n",
    "#logN = np.log(1 / ( ((2*np.pi)**0.5)*X_train_stds ) ) - (X_minus_mu_sq/(2*X_train_stds_sq))\n",
    "#print(logN.shape)\n",
    "\n",
    "logN_not = np.log(1 / ( ((2*np.pi)**0.5)*not_stds ) ) - (not_minus_mu_sq/(2*not_stds**2))\n",
    "logN_spam = np.log(1 / ( ((2*np.pi)**0.5)*spam_stds ) ) - (spam_minus_mu_sq/(2*spam_stds**2))\n",
    "\n",
    "sum_not = np.sum(logN_not, axis=1) + np.log(prior_not)\n",
    "sum_spam = np.sum(logN_spam, axis=1) + np.log(prior_spam)\n",
    "\n",
    "sum_joined = np.concatenate( (sum_not.reshape(-1,1), sum_spam.reshape(-1,1)), axis = 1)\n",
    "\n",
    "print(sum_joined.shape)\n",
    "argmax_logN = np.argmax(sum_joined, axis = 1) #predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.834419817470665\n",
      "precision = 0.7228813559322034\n",
      "recall = 0.9404630650496141\n",
      "confusion matrix\n",
      "[[1067  327]\n",
      " [  54  853]]\n"
     ]
    }
   ],
   "source": [
    "#Results\n",
    "accuracy = np.sum(argmax_logN == y_test) / len(y_test)\n",
    "print(\"accuracy = \" + str(accuracy))\n",
    "\n",
    "precision = np.sum(np.logical_and(argmax_logN,y_test)) / np.sum(argmax_logN)\n",
    "print(\"precision = \" + str(precision))\n",
    "\n",
    "recall = np.sum(np.logical_and(argmax_logN,y_test)) / np.sum(y_test)\n",
    "print(\"recall = \" + str(recall))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, argmax_logN)\n",
    "print(\"confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Discussion\n",
    "\n",
    "The recall was very high at ~94%, meaning almost all spam mails were caught. However, that came at a price with a much lower precision value of ~72%, suggesting the Naive Bayes classifier was over-zealous in detecting spam, and incorrectly lumped a number of real emails as spam, leaving us with a decent, but not great precision of ~83%.\n",
    "\n",
    "As this is considerably worse than the SVMs in HW3 did, which had accuracy, precision, and recall values all near 90%, leaves us to conclude that the Naive Bayes bias is incorrect on the independence assumption. Logically, we would expect spam mail attributes to have some dependency (capital letters and dollar signs seem a likely pair!). However, even with the incorrect assumption, Naive Bayes does OK with an overall accuracy in the 80s, but given the nature of the task, we would value precision greatly to avoid mis-characterizing important emails, and so ~300/1400 emails incorrectly labeled as spam is unacceptable for this task.\n",
    "\n",
    "Other reasons Naive Bayes may have struggled would be the equal weighting given to all the attributes, as every probability is simply multipled together. As seen in homework 3, there were a number of high-weight attributes that played a significant role in the classification.\n",
    "\n",
    "## Part 2: Logistic Regression\n",
    "\n",
    "Here, we use the scikit_learn library to perform Logistic Regression on the datase, with the \"liblinear\" solver setting.\n",
    "(https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9287266405910474\n",
      "precision = 0.9169472502805837\n",
      "recall = 0.9007717750826902\n",
      "confusion matrix\n",
      "[[1320   74]\n",
      " [  90  817]]\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/52640386/how-do-i-solve-the-future-warning-min-groups-self-n-splits-warning-in\n",
    "#https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions\n",
    "\n",
    "logisticRegr = LogisticRegression(solver='liblinear') #lbfgs, liblinear\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "\n",
    "#Results\n",
    "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "print(\"accuracy = \" + str(accuracy))\n",
    "\n",
    "precision = np.sum(np.logical_and(predictions,y_test)) / np.sum(predictions)\n",
    "print(\"precision = \" + str(precision))\n",
    "\n",
    "recall = np.sum(np.logical_and(predictions,y_test)) / np.sum(y_test)\n",
    "print(\"recall = \" + str(recall))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(\"confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Discussion\n",
    "\n",
    "[1] https://medium.com/@sangha_deb/naive-bayes-vs-logistic-regression-a319b07a5d4c\n",
    "\n",
    "The logistic regression results were all in the 90s (93, 92, 90 for accuracy, precision, and recall), notably performing even better than homework 3's SVMs by about 1% in each category, and far better than the suboptimal results from Part 1's Naive Bayes.\n",
    "\n",
    "Although they Naive Bayes and Logistic Regression are both linear classifiers, the first is a generative model, and the second is a discriminative model. Additionally, according to the source above [1], Logistic Regression performs better with a larger dataset than Naive Bayes. In our case, Logistic Regression was far better even without a massive dataset, suggests the dataset does not follow the Naive Bayes bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2]\n",
      " [1 1 1]]\n",
      "[0 1 2]\n",
      "[[ 2  1  0]\n",
      " [ 1  0 -1]]\n",
      "[[4 4 4]\n",
      " [1 1 1]]\n",
      "[[2.   1.   0.5 ]\n",
      " [1.   0.5  0.25]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Numpy array broadcasting\n",
    "a = np.array([[2, 2, 2], [1, 1, 1]])\n",
    "print (a)\n",
    "b = np.array([0, 1, 2])\n",
    "print(b)\n",
    "print(a-b)\n",
    "\n",
    "#array squaring\n",
    "print(a**2)\n",
    "\n",
    "#division broadcasting\n",
    "c = np.array([1, 2, 4])\n",
    "print(a/c)\n",
    "\n",
    "#Transpose\n",
    "#https://stackoverflow.com/questions/36384760/transforming-a-row-vector-into-a-column-vector-in-numpy\n",
    "    \n",
    "#Sorting array by key\n",
    "#https://stackoverflow.com/questions/10695139/sort-a-list-of-tuples-by-2nd-item-integer-value\n",
    "    \n",
    "#Checking array equality percentage\n",
    "#https://stackoverflow.com/questions/25490641/check-how-many-elements-are-equal-in-two-numpy-arrays-python\n",
    "    \n",
    "#Precision Checking, logical AND on arrays\n",
    "d = [0, 1, 0, 1, 0, 0, 0, 1, 1, 1]\n",
    "e = [1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "np_and = np.logical_and(d,e)\n",
    "print(sum(np_and))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
